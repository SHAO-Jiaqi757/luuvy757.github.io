<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jiaqi&#39;s Blog</title>
  
  
  <link href="https://luuvy757.github.io/atom.xml" rel="self"/>
  
  <link href="https://luuvy757.github.io/"/>
  <updated>2022-03-09T15:22:22.011Z</updated>
  <id>https://luuvy757.github.io/</id>
  
  <author>
    <name>Jiaqi Shao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FL Algorithms</title>
    <link href="https://luuvy757.github.io/2022/03/09/FL-Algorithms/"/>
    <id>https://luuvy757.github.io/2022/03/09/FL-Algorithms/</id>
    <published>2022-03-09T14:03:03.000Z</published>
    <updated>2022-03-09T15:22:22.011Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Device $i$ has $N_{i}$ training samples: $z_{i,1}, z_{i,2}, …, z_{i,N_{i}}$   </li><li>$f_{i}(w, z_{i,j})$: loss of the model on training sample $z_{i,j}$     </li><li>$F_{i}(w) = \frac{1}{N_{i}} \sum_{j=1}^{N_{i}}f_{i}(w, z_{i,j})$: loss function of device $i$    </li></ul><h2 id="Formula-1-One-Model-Fits-All-Formulation"><a href="#Formula-1-One-Model-Fits-All-Formulation" class="headerlink" title="Formula 1: One-Model-Fits-All Formulation"></a>Formula 1: One-Model-Fits-All Formulation</h2><script type="math/tex; mode=display">minimize_{w} \sum_{i=1}^{n}\alpha_{i}F_{i}(w)</script><p>Common practice: $\alpha_{i} = \frac{N_{i}}{N}, N=\sum_{k=1}^{n} N_{k}$:</p><script type="math/tex; mode=display">minimize_{w}\frac{1}{N}\sum_{i=1}^{n}\sum_{j=1}^{N_{i}}f_{i}(w, z_{i,j})</script><p>(Less effective and even undesirable)</p><h2 id="Formula-2-Full-personalized-model"><a href="#Formula-2-Full-personalized-model" class="headerlink" title="Formula 2: Full personalized model"></a>Formula 2: Full personalized model</h2><script type="math/tex; mode=display">minimize_{w_{0}, \{w_{i}\}_{i=1}^{n}} \sum_{i=1}^{n}\alpha_{i}(F_{i}(w_{i} + \frac{\lambda_{i}}{2}||w_{i}-w_{0}||^{2}))</script><ul><li>$w_{i}$: personalized model parameters.</li><li>$\lambda_{i}$: regularization weights.</li><li>$w_{0}$: reference model maintained by server.</li></ul><p>(Full model personalization: $w_{i}, w_{0}$, <strong>memory cost</strong>)</p><h2 id="Formula-3-Partial-personalized-model"><a href="#Formula-3-Partial-personalized-model" class="headerlink" title="Formula 3: Partial personalized model"></a>Formula 3: Partial personalized model</h2><ul><li>model parameters on device $i$: $w_{i} = (u,v_{i})$</li><li>$u$: shared parameters $u \in R^{d_{0}}$</li><li>$v_{i}$: personalized parameters $v_{i} \in R^{d_{i}}$</li></ul><script type="math/tex; mode=display">minimize_{u, \{v_{i}\}_{i=1}^{n}}\sum_{i=1}^{n}\alpha_{i}F_{i}(u,v_{i})</script><p><strong>Problems</strong>: different  of</p><ul><li>$\dim v_{i}$ </li><li>Number of parameters </li><li>Architecture </li></ul><p><strong>Solution</strong>: <em>FedSim, FedAlt</em></p><h2 id="Standard-FL-protocol"><a href="#Standard-FL-protocol" class="headerlink" title="Standard FL protocol:"></a>Standard FL protocol:</h2><img src="/2022/03/09/FL-Algorithms/FL_standard.png" class=""><ol><li>During each round, the <strong>server</strong> <em>randomly</em> selects a subset of the devices for <strong>update and broadcasts</strong> the current global version of the <strong>shared parameters</strong> to devices in the subset. </li><li>Each <strong>selected device</strong> then<br>performs one or more steps of (stochastic) gradient descent to <strong>update both the shared parameters and the personal parameters</strong>, and <strong>sends the updated shared parameters to the server</strong> for aggregation.</li><li>The <strong>updated personal parameters</strong> are kept local at the device to serve as the initial states when the device is selected for another update. <h2 id="FedSim-FedAlt"><a href="#FedSim-FedAlt" class="headerlink" title="FedSim, FedAlt"></a><em>FedSim, FedAlt</em></h2><img src="/2022/03/09/FL-Algorithms/FedSim_FedAlt.png" class=""></li></ol><ul><li><p>In <em>FedSim</em>, the <strong>shared and personal parameters</strong> are <strong>updated simultaneously</strong> during each local iteration.</p></li><li><p>In <em>FedAlt</em>, the devices <strong>first update the personal parameters</strong> with the received shared parameters fixed and <strong>then update the shared parameters</strong> with the new personal parameters fixed.</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Device $i$ has $N_{i}$ training samples: $z_{i,1}, z_{i,2}, …, z_{i,N_{i}}$   &lt;/li&gt;
&lt;li&gt;$f_{i}(w, z_{i,j})$: loss of the model on t</summary>
      
    
    
    
    <category term="FL" scheme="https://luuvy757.github.io/categories/FL/"/>
    
    
  </entry>
  
  <entry>
    <title>FL using Flower on device</title>
    <link href="https://luuvy757.github.io/2022/01/21/FL-using-Flower-on-device/"/>
    <id>https://luuvy757.github.io/2022/01/21/FL-using-Flower-on-device/</id>
    <published>2022-01-21T04:59:06.000Z</published>
    <updated>2022-02-09T03:48:05.160Z</updated>
    
    <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a><a href="/2022/01/23/FL-using-Flower-on-device/About-Flower/" title="About Flower">About Flower</a></h2><h2 id="Flower-Android"><a href="#Flower-Android" class="headerlink" title="Flower + Android"></a>Flower + Android</h2><img src="/2022/01/21/FL-using-Flower-on-device/flwr-android.png" class="" title="Overview"><h3 id="Run-Federated-Learning-on-Android-Devices-TF-Lite-Flower"><a href="#Run-Federated-Learning-on-Android-Devices-TF-Lite-Flower" class="headerlink" title="Run Federated Learning on Android Devices (TF Lite + Flower)"></a>Run Federated Learning on Android Devices (TF Lite + Flower)</h3><p><a href="https://flower.dev/blog/2021-12-15-federated-learning-on-android-devices-with-flower">Tutorial blog</a><br><a href="https://github.com/adap/flower/tree/main/examples/android">Github: Flower Android Example (TensorFlowLite)</a></p><ol><li><p><strong>Setup the model definitions</strong></p><blockquote><p>tflite_convertor/convert_to_tflite.py<br><a href="#FL-Model-Personalization">TF Model Personalization</a> requires defining two architectures:</p></blockquote><p> |  |  |<br> | —————- | —————- |<br> | <strong>Base Model</strong> | A pre-trained feature extractor (e.g., ResNet50 trained on ImageNet) which is not updated during on-device training. |<br> | <strong>Head Model</strong> | Like a task-specific classifer which is randomly initialized and trained on the local data. |</p><p> Both Models can be configured in <strong>tflite_convertor/convert_to_tflite.py</strong>, and converted into “tflite_model”</p></li></ol><ol><li><p><strong>Android Client</strong> </p><blockquote><p><code>client</code> folder  </p></blockquote><ul><li><strong>Modifying App’s Interface and Functionalities</strong><br>flwr/android_client/MainActivity.java<br><code>loadData</code>, <code>connect</code>, <code>runGRCP</code></li><li><p><strong>Modifying Flower Client</strong><br>flwr/android_client/FlowerClient.java<br><strong>LoadData</strong> (Also, checking: src/main/assets/data,<br>  flwr/android_client/TransferLearningModelWrapper.java)<br><strong>Loss Callback</strong>          </p></li><li><p><strong>Add tflite_model</strong><br>src/main/assets/model<br>build.gradle(Module: client.app)</p></li></ul></li><li><p><strong>Server</strong></p><blockquote><p>server.py</p></blockquote><p>Usage: <code>Strategy</code> configuration</p><p>More about Strategy: <a href="https://flower.dev/docs/strategies.html">https://flower.dev/docs/strategies.html</a></p></li><li><p>Log</p><ul><li><p>Server Log</p><img src="/2022/01/21/FL-using-Flower-on-device/demo-server-log.png" class=""></li><li><p>Client Log (Two devices: Huawei Honor (Android 9) and Huawei M6 (Android 10))</p><img src="/2022/01/21/FL-using-Flower-on-device/demo-device-log.jpg" class=""></li></ul></li></ol><h2 id="Flower-Embedded"><a href="#Flower-Embedded" class="headerlink" title="Flower + Embedded"></a>Flower + Embedded</h2><img src="/2022/01/21/FL-using-Flower-on-device/flwr-embedded.png" class="" title="Overview"><hr><h2 id="FL-Model-Personalization"><a href="#FL-Model-Personalization" class="headerlink" title="FL Model Personalization"></a>FL Model Personalization</h2><p><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization">TensorFlow Lite Example On-device Model Personalization</a></p><h3 id="Prepare-the-TfLite-model"><a href="#Prepare-the-TfLite-model" class="headerlink" title="Prepare the TfLite model"></a>Prepare the TfLite model</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/model_personalization</span><br><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── android</span><br><span class="line">├── app_screenshot.png</span><br><span class="line">└── transfer_learning</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># under /transfer_learning </span></span><br><span class="line"><span class="comment"># Generate the model flatbuffer file `model.tflite`</span></span><br><span class="line">python generate_training_model.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># under /model_personalization</span></span><br><span class="line"><span class="comment"># Copy over the flatbuffer file to the `android` assets directory.</span></span><br><span class="line">cp transfer_learning/model.tflite android/app/src/main/assets/model/model.tflite</span><br></pre></td></tr></table></figure><h3 id="Install-and-run-the-application-on-Device"><a href="#Install-and-run-the-application-on-Device" class="headerlink" title="Install and run the application on Device"></a>Install and run the application on Device</h3><ol><li><p>Open Android Studio and import the project (the <code>/android</code> folder)</p><img src="/2022/01/21/FL-using-Flower-on-device/android-studio-import-demo.png" class=""></li><li><p>Connect with device and run the code. </p><img src="/2022/01/21/FL-using-Flower-on-device/device-connection.png" class=""></li></ol><h3 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h3><ol><li><p><code>$ python server.py</code> Error: No attribute FedAvgAndroid</p><blockquote><p>Install the latest version of the flower from the github:</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/adap/flower.git</span><br></pre></td></tr></table></figure></blockquote></li><li><p>Failed install app: app cannot be installed for “unpublished vision”</p><blockquote><p><code>/android</code> folder, in <code>gradle.properties</code> add <code>android.injected.testOnly=false</code></p></blockquote></li><li><p>USB connection</p><blockquote><p>Open USB developer option on device</p></blockquote></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;&quot;&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title=&quot;&quot;&gt;&lt;/a&gt;&lt;a href=&quot;/2022/01/23/FL-using-Flower-on-device/About-Flower/&quot; title=&quot;About Flower&quot;&gt;Abo</summary>
      
    
    
    
    <category term="FL" scheme="https://luuvy757.github.io/categories/FL/"/>
    
    
  </entry>
  
</feed>
